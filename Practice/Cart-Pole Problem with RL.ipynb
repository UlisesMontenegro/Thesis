{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym #Open AI library\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\envs\\registration.py:555: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "print(env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1 #Learning Rate\n",
    "gamma = 0.95 #Discount Factor\n",
    "\n",
    "epochs = 60000 #How many iterations\n",
    "total_time = 0\n",
    "total_reward = 0\n",
    "prev_reward = 0\n",
    "\n",
    "Observation = [30,30,50,50]\n",
    "step_size = np.array([.25,.25, .01, .01])\n",
    "\n",
    "epsilon = 1\n",
    "epsilon_decay_value = 0.9995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.random.uniform(low=0, high=1, size=(Observation+[env.action_space.n])) #Randomly initializing Q-Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method used to discretize the state space given by OpanAI Gym library\n",
    "def discrete_state(state):\n",
    "    discrete_state = state/step_size + np.array([15,12,1,10])\n",
    "    return tuple(discrete_state.astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Uli\\FIUBA\\Tesis\\Thesis\\Cart-Pole Problem with RL.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Uli/FIUBA/Tesis/Thesis/Cart-Pole%20Problem%20with%20RL.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(env\u001b[39m.\u001b[39;49mreset()\u001b[39m/\u001b[39;49mstep_size)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "print(env.reset()/step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Uli\\FIUBA\\Tesis\\Thesis\\Cart-Pole Problem with RL.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Uli/FIUBA/Tesis/Thesis/Cart-Pole%20Problem%20with%20RL.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Uli/FIUBA/Tesis/Thesis/Cart-Pole%20Problem%20with%20RL.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     t_initial \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Uli/FIUBA/Tesis/Thesis/Cart-Pole%20Problem%20with%20RL.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     discrete_state \u001b[39m=\u001b[39m discrete_state(env\u001b[39m.\u001b[39;49mreset())\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Uli/FIUBA/Tesis/Thesis/Cart-Pole%20Problem%20with%20RL.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     done \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39m#Control boolean\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Uli/FIUBA/Tesis/Thesis/Cart-Pole%20Problem%20with%20RL.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     epoch_reward \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;32md:\\Uli\\FIUBA\\Tesis\\Thesis\\Cart-Pole Problem with RL.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Uli/FIUBA/Tesis/Thesis/Cart-Pole%20Problem%20with%20RL.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdiscrete_state\u001b[39m(state):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Uli/FIUBA/Tesis/Thesis/Cart-Pole%20Problem%20with%20RL.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     discrete_state \u001b[39m=\u001b[39m (state\u001b[39m/\u001b[39;49mstep_size) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m15\u001b[39m,\u001b[39m12\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m10\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Uli/FIUBA/Tesis/Thesis/Cart-Pole%20Problem%20with%20RL.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(discrete_state\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint))\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs+1):\n",
    "    t_initial = time.time()\n",
    "\n",
    "    discrete_state = discrete_state(env.reset()) #Get the discrete state for the restarted environment, so we know what's going on\n",
    "\n",
    "    done = False #Control boolean\n",
    "\n",
    "    epoch_reward = 0\n",
    "\n",
    "    if epoch % 1000 == 0: #I'm going to print every each 1000 epochs\n",
    "        print(\"Episode: \" + str(epoch))\n",
    "\n",
    "    while not done:\n",
    "        if np.random.random() > epsilon: #If some random number is greater than epsilon\n",
    "            action = np.argmax(q_table[discrete_state]) #Look into the Q-Table for the action that maximizes the reward for the actual state (Exploitation)\n",
    "        else:\n",
    "            action = np.random.randint(0, env.action_space.n) #Pick a random action from the action space (Exploration)\n",
    "    \n",
    "    new_state, reward, done, _ = env.step(action) #Update the environment\n",
    "\n",
    "    epoch_reward += reward\n",
    "\n",
    "    new_discrete_state = discrete_state(new_state)\n",
    "\n",
    "    if epoch % 1000 == 0: #I'm rendering the environment every each 1000 epochs\n",
    "        env.render()\n",
    "    \n",
    "    if not done: #If the game is not over, update the Q-Table\n",
    "        max_new_q = np.max(q_table[new_discrete_state])\n",
    "        current_q = q_table[discrete_state + (action,)]\n",
    "        new_q = current_q + lr*(reward + (gamma*max_new_q) - current_q)\n",
    "        q_table[discrete_state + (action,)] = new_q\n",
    "\n",
    "    discrete_state = new_discrete_state #Updating the state\n",
    "\n",
    "    if epsilon > 0.05:\n",
    "        if epoch_reward > prev_reward and epoch > 10000:\n",
    "            epsilon = math.pow(epsilon_decay_value, epoch-10000)\n",
    "        if epoch % 500 == 0:\n",
    "            print(\"Epsilon: \" + str(epsilon))\n",
    "\n",
    "    #Calculating total times\n",
    "    tfinal = time.time()\n",
    "    episode_total_time = tfinal - t_initial\n",
    "    total_time += episode_total_time\n",
    "\n",
    "    #Calculating total rewards\n",
    "    total_reward += epoch_reward\n",
    "    prev_reward = epoch_reward\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        mean_time = total_time/1000\n",
    "        print(\"Average Time: \" + str(mean_time))\n",
    "        total_time = 0\n",
    "        mean_reward = total_reward/1000\n",
    "        print(\"Average Reward: \" + str(mean_reward))\n",
    "        total_reward = 0\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
